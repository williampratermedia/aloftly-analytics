---
phase: 01-foundation
plan: 02
type: execute
wave: 2
depends_on:
  - 01-01
files_modified:
  - src/db/schema/auth.ts
  - src/db/schema/metrics.ts
  - src/db/schema/sync.ts
  - src/db/schema/index.ts
  - src/db/migrations/
autonomous: true
requirements:
  - FOUN-01
  - FOUN-06
  - FOUN-07
  - FOUN-08
  - FOUN-09
  - FOUN-10
  - FOUN-11
  - FOUN-12

user_setup:
  - service: supabase
    why: "Custom access token hook must be registered in Supabase Dashboard for JWT claims to work"
    dashboard_config:
      - task: "Register the custom access token hook: go to Auth > Hooks > Custom Access Token, select the PostgreSQL function public.custom_access_token_hook, and enable it"
        location: "Supabase Dashboard -> Authentication -> Hooks -> Custom Access Token"

must_haves:
  truths:
    - "Organizations, workspaces, stores, and org_members tables exist with correct foreign keys"
    - "metric_events table is partitioned by range on recorded_at with monthly partitions"
    - "metric_definitions table exists with key, source, displayName, unit, aggregation, category columns"
    - "sync_jobs and integration_connections tables exist with status tracking columns"
    - "Vault helper functions exist for storing and retrieving encrypted credentials"
    - "RLS policies enforce org_id isolation using auth.jwt() claims on all tenant-scoped tables"
    - "Organizations table has plan_tier, feature_flags, and white_label_config columns"
    - "Custom access token hook injects org_id and user_role into JWT claims from org_members table"
    - "A user in Org A cannot read rows belonging to Org B — RLS blocks the query at the database level, returning zero rows"
  artifacts:
    - path: "src/db/schema/auth.ts"
      provides: "Org, workspace, store, org_members table definitions + enums"
      contains: "organizations"
    - path: "src/db/schema/metrics.ts"
      provides: "metric_events (type reference only) and metric_definitions table definitions"
      contains: "metricDefinitions"
    - path: "src/db/schema/sync.ts"
      provides: "sync_jobs and integration_connections table definitions"
      contains: "syncJobs"
    - path: "src/db/schema/index.ts"
      provides: "Barrel export of all schema modules"
    - path: "src/db/migrations/"
      provides: "Generated Drizzle migration files including raw SQL for partitioned metric_events and Vault functions"
  key_links:
    - from: "src/db/schema/auth.ts"
      to: "src/db/schema/sync.ts"
      via: "Foreign key references (organizations.id)"
      pattern: "references.*organizations"
    - from: "src/db/schema/metrics.ts"
      to: "src/db/schema/auth.ts"
      via: "org_id and store_id foreign key references"
      pattern: "org_id.*references"
    - from: "src/db/migrations/"
      to: "metric_events partitioned table"
      via: "Raw SQL migration for PARTITION BY RANGE"
      pattern: "partition by range"
---

<objective>
Create the complete multi-tenant database schema with Drizzle ORM — organizations, workspaces, stores, org_members, metric_events (partitioned), metric_definitions, sync_jobs, and integration_connections. Set up RLS policies on all tenant-scoped tables and Vault helper functions for encrypted credential storage.

Purpose: The schema is the foundation every future phase depends on. Getting multi-tenancy, partitioning, and RLS right here prevents costly refactoring later.
Output: Drizzle schema files, generated migrations, and a fully provisioned Supabase database with RLS active.
</objective>

<execution_context>
@C:/Users/billy/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/billy/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-foundation/01-RESEARCH.md
@.planning/phases/01-foundation/01-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Drizzle schema files for all multi-tenant tables</name>
  <files>
    src/db/schema/auth.ts
    src/db/schema/metrics.ts
    src/db/schema/sync.ts
    src/db/schema/index.ts
  </files>
  <action>
    1. Create `src/db/schema/auth.ts` with the following tables and enums:

       **Enums:**
       - `planTierEnum`: 'starter', 'professional', 'agency', 'enterprise'
       - `orgRoleEnum`: 'owner', 'admin', 'member', 'viewer'

       **organizations table:**
       - id (uuid, PK, defaultRandom)
       - name (text, notNull)
       - slug (varchar 100, notNull, unique)
       - planTier (planTierEnum, notNull, default 'starter') — FOUN-12
       - featureFlags (jsonb, notNull, default {}) — FOUN-11
       - whiteLabelConfig (jsonb, notNull, default {}) — FOUN-10
       - createdAt, updatedAt (timestamptz, notNull, defaultNow)

       **workspaces table:**
       - id (uuid, PK, defaultRandom)
       - orgId (uuid, notNull, FK → organizations.id, onDelete cascade)
       - name (text, notNull)
       - slug (varchar 100, notNull)
       - createdAt (timestamptz, notNull, defaultNow)
       - Index on orgId

       **stores table:**
       - id (uuid, PK, defaultRandom)
       - orgId (uuid, notNull, FK → organizations.id, onDelete cascade)
       - workspaceId (uuid, notNull, FK → workspaces.id, onDelete cascade)
       - shopifyDomain (varchar 255, notNull)
       - displayName (text, notNull)
       - createdAt (timestamptz, notNull, defaultNow)
       - Indexes on orgId, workspaceId

       **orgMembers table:**
       - id (uuid, PK, defaultRandom)
       - orgId (uuid, notNull, FK → organizations.id, onDelete cascade)
       - userId (uuid, notNull) — references auth.users(id) but NOT a Drizzle FK (cross-schema)
       - role (orgRoleEnum, notNull, default 'member')
       - invitedAt (timestamptz, nullable)
       - joinedAt (timestamptz, nullable)
       - Indexes on orgId, userId
       - Unique constraint on (orgId, userId) to prevent duplicate memberships

       **workspaceMembers table:**
       - id (uuid, PK, defaultRandom)
       - workspaceId (uuid, notNull, FK → workspaces.id, onDelete cascade)
       - userId (uuid, notNull)
       - createdAt (timestamptz, notNull, defaultNow)
       - Indexes on workspaceId, userId
       - Unique constraint on (workspaceId, userId)

    2. Create `src/db/schema/metrics.ts`:

       **metricDefinitions table:** — FOUN-07
       - id (uuid, PK, defaultRandom)
       - key (varchar 100, notNull, unique) — e.g. 'clarity.rage_clicks'
       - source (varchar 50, notNull) — e.g. 'clarity'
       - displayName (text, notNull)
       - unit (varchar 50, nullable) — 'count', 'percent', 'currency'
       - aggregationMethod (varchar 50, notNull, default 'sum')
       - category (varchar 50, nullable) — 'engagement', 'revenue', 'ab_test'
       - description (text, nullable)
       - metadata (jsonb, notNull, default {})
       - createdAt (timestamptz, notNull, defaultNow)

       **metric_events Drizzle reference:** Define a type-only reference for metric_events columns so other Drizzle code can reference the shape, but the actual CREATE TABLE is raw SQL in the migration (because Drizzle cannot generate PARTITION BY). Add a comment: "// Table created via raw SQL migration — see 0001_metric_events.sql"

    3. Create `src/db/schema/sync.ts`:

       **Enums:**
       - `syncStatusEnum`: 'pending', 'running', 'succeeded', 'failed', 'retrying'

       **syncJobs table:** — FOUN-08
       - id (uuid, PK, defaultRandom)
       - orgId (uuid, notNull, FK → organizations.id, onDelete cascade)
       - storeId (uuid, notNull, FK → stores.id, onDelete cascade)
       - source (varchar 50, notNull)
       - status (syncStatusEnum, notNull, default 'pending')
       - cursor (text, nullable)
       - startedAt (timestamptz, nullable)
       - completedAt (timestamptz, nullable)
       - durationMs (integer, nullable)
       - errorDetails (jsonb, nullable)
       - createdAt (timestamptz, notNull, defaultNow)
       - Index on (orgId, storeId)

       **integrationConnections table:**
       - id (uuid, PK, defaultRandom)
       - orgId (uuid, notNull, FK → organizations.id, onDelete cascade)
       - storeId (uuid, notNull, FK → stores.id, onDelete cascade)
       - source (varchar 50, notNull)
       - isActive (boolean, notNull, default true)
       - vaultSecretId (uuid, nullable) — stores Vault secret ID, not the credential itself
       - lastSyncAt (timestamptz, nullable)
       - lastSyncStatus (syncStatusEnum, nullable)
       - errorDetails (jsonb, nullable)
       - settings (jsonb, notNull, default {})
       - createdAt, updatedAt (timestamptz, notNull, defaultNow)
       - Unique constraint on (storeId, source) — one connection per source per store
       - Index on orgId

    4. Create `src/db/schema/index.ts` — barrel export all tables, enums, and types from auth.ts, metrics.ts, sync.ts.

    IMPORTANT: Follow the exact patterns from 01-RESEARCH.md. Use `drizzle-orm/pg-core` imports. Use `uuid('id').primaryKey().defaultRandom()` pattern for all primary keys.
  </action>
  <verify>
    - All schema files compile without TypeScript errors: `npx tsc --noEmit`
    - `src/db/schema/index.ts` exports all tables and enums
    - organizations table has planTier, featureFlags, whiteLabelConfig columns
    - syncJobs has cursor column for incremental syncing
    - integrationConnections has vaultSecretId column
  </verify>
  <done>
    All Drizzle schema files exist with correct table definitions, foreign keys, indexes, enums, and a barrel export. The schema covers the complete org → workspace → store hierarchy, metric_definitions, sync_jobs, and integration_connections.
  </done>
</task>

<task type="auto">
  <name>Task 2: Generate migrations, create partitioned metric_events, RLS policies, and Vault functions</name>
  <files>
    src/db/migrations/
  </files>
  <action>
    1. Generate the initial Drizzle migration:
       ```bash
       npx drizzle-kit generate
       ```
       This creates migration SQL for all Drizzle-defined tables.

    2. Create a custom SQL migration file for `metric_events` (FOUN-06) — Drizzle cannot generate PARTITION BY. Create the file manually in `src/db/migrations/` with the next sequential name:

       **Partitioning rationale (Claude's discretion per CONTEXT.md):** REQUIREMENTS.md says "partitioned by (store_id, recorded_at)" but PostgreSQL range partitioning only supports a single partition key expression. Using RANGE on recorded_at only is the correct approach: store_id filtering happens via the `metric_events_store_recorded_idx` composite index, and monthly recorded_at partitions align with the 7/30/90-day CRO query patterns. Composite (store_id, recorded_at) would require list-range sub-partitioning — adding operational complexity (one partition per store per month) with no query benefit since store_id is already indexed.

       ```sql
       -- metric_events: partitioned by range on recorded_at (monthly partitions)
       -- See partitioning rationale above — RANGE on recorded_at only is intentional
       CREATE TABLE IF NOT EXISTS public.metric_events (
         id          uuid          NOT NULL DEFAULT gen_random_uuid(),
         store_id    uuid          NOT NULL,
         org_id      uuid          NOT NULL,
         source      varchar(50)   NOT NULL,
         metric_key  varchar(100)  NOT NULL,
         value       numeric(20,4) NOT NULL,
         recorded_at timestamptz   NOT NULL,
         synced_at   timestamptz   NOT NULL DEFAULT now(),
         dimensions  jsonb         NOT NULL DEFAULT '{}',
         PRIMARY KEY (id, recorded_at)
       ) PARTITION BY RANGE (recorded_at);

       -- Indexes (inherited by all partitions)
       CREATE INDEX metric_events_store_recorded_idx ON public.metric_events (store_id, recorded_at DESC);
       CREATE INDEX metric_events_org_id_idx ON public.metric_events (org_id);
       CREATE INDEX metric_events_source_key_idx ON public.metric_events (source, metric_key);
       CREATE INDEX metric_events_dimensions_gin_idx ON public.metric_events USING gin (dimensions);

       -- Initial monthly partitions (current month + 3 months ahead)
       CREATE TABLE metric_events_2026_02 PARTITION OF metric_events FOR VALUES FROM ('2026-02-01') TO ('2026-03-01');
       CREATE TABLE metric_events_2026_03 PARTITION OF metric_events FOR VALUES FROM ('2026-03-01') TO ('2026-04-01');
       CREATE TABLE metric_events_2026_04 PARTITION OF metric_events FOR VALUES FROM ('2026-04-01') TO ('2026-05-01');
       CREATE TABLE metric_events_2026_05 PARTITION OF metric_events FOR VALUES FROM ('2026-05-01') TO ('2026-06-01');
       ```

    3. Create a custom SQL migration for RLS policies (FOUN-04). All policies use `auth.jwt()->>'org_id'` — NO subqueries:

       ```sql
       -- Enable RLS on all tenant-scoped tables
       ALTER TABLE public.organizations ENABLE ROW LEVEL SECURITY;
       ALTER TABLE public.workspaces ENABLE ROW LEVEL SECURITY;
       ALTER TABLE public.stores ENABLE ROW LEVEL SECURITY;
       ALTER TABLE public.org_members ENABLE ROW LEVEL SECURITY;
       ALTER TABLE public.workspace_members ENABLE ROW LEVEL SECURITY;
       ALTER TABLE public.metric_events ENABLE ROW LEVEL SECURITY;
       ALTER TABLE public.metric_definitions ENABLE ROW LEVEL SECURITY;
       ALTER TABLE public.sync_jobs ENABLE ROW LEVEL SECURITY;
       ALTER TABLE public.integration_connections ENABLE ROW LEVEL SECURITY;

       -- Org isolation policies (JWT claim based, no subqueries)
       CREATE POLICY org_isolation ON public.organizations FOR ALL USING (id = (auth.jwt()->>'org_id')::uuid);
       CREATE POLICY org_isolation ON public.workspaces FOR ALL USING (org_id = (auth.jwt()->>'org_id')::uuid);
       CREATE POLICY org_isolation ON public.stores FOR ALL USING (org_id = (auth.jwt()->>'org_id')::uuid);
       CREATE POLICY org_isolation ON public.org_members FOR ALL USING (org_id = (auth.jwt()->>'org_id')::uuid);
       CREATE POLICY org_isolation ON public.sync_jobs FOR ALL USING (org_id = (auth.jwt()->>'org_id')::uuid);
       CREATE POLICY org_isolation ON public.integration_connections FOR ALL USING (org_id = (auth.jwt()->>'org_id')::uuid);
       CREATE POLICY org_isolation ON public.metric_events FOR ALL USING (org_id = (auth.jwt()->>'org_id')::uuid);

       -- metric_definitions is global (not org-scoped) — read-only for authenticated users
       CREATE POLICY read_definitions ON public.metric_definitions FOR SELECT USING (auth.role() = 'authenticated');

       -- workspace_members: user can see their own workspace memberships within their org
       CREATE POLICY org_isolation ON public.workspace_members FOR ALL
         USING (workspace_id IN (
           SELECT w.id FROM public.workspaces w WHERE w.org_id = (auth.jwt()->>'org_id')::uuid
         ));
       ```

       NOTE on workspace_members policy: This is the ONE exception where a subquery is acceptable — workspace_members does not have a direct org_id column. The subquery is on workspaces (small cardinality per org) and is acceptable. Document this exception in a SQL comment.

    4. Create a custom SQL migration for Vault helper functions (FOUN-09):

       ```sql
       -- Vault credential storage functions (service_role only)
       CREATE SCHEMA IF NOT EXISTS private;

       CREATE OR REPLACE FUNCTION private.store_integration_credential(
         p_secret text, p_name text, p_description text DEFAULT NULL
       ) RETURNS uuid LANGUAGE plpgsql SECURITY DEFINER SET search_path = public, vault AS $$
       DECLARE secret_id uuid;
       BEGIN
         SELECT vault.create_secret(p_secret, p_name, p_description) INTO secret_id;
         RETURN secret_id;
       END;
       $$;

       CREATE OR REPLACE FUNCTION private.get_integration_credential(p_secret_id uuid)
       RETURNS text LANGUAGE plpgsql SECURITY DEFINER SET search_path = public, vault AS $$
       DECLARE secret_value text;
       BEGIN
         SELECT decrypted_secret INTO secret_value FROM vault.decrypted_secrets WHERE id = p_secret_id;
         RETURN secret_value;
       END;
       $$;

       -- Restrict to service_role only
       REVOKE ALL ON FUNCTION private.store_integration_credential FROM PUBLIC, anon, authenticated;
       GRANT EXECUTE ON FUNCTION private.store_integration_credential TO service_role;
       REVOKE ALL ON FUNCTION private.get_integration_credential FROM PUBLIC, anon, authenticated;
       GRANT EXECUTE ON FUNCTION private.get_integration_credential TO service_role;
       ```

    5. Create a custom SQL migration for the org provisioning trigger (fires on new auth.users insert):

       ```sql
       CREATE OR REPLACE FUNCTION public.handle_new_user()
       RETURNS trigger LANGUAGE plpgsql SECURITY DEFINER SET search_path = public AS $$
       DECLARE
         new_org_id uuid;
         new_workspace_id uuid;
       BEGIN
         INSERT INTO public.organizations (name, slug, plan_tier)
         VALUES (
           split_part(NEW.email, '@', 2),
           lower(replace(split_part(NEW.email, '@', 2), '.', '-')) || '-' || substr(gen_random_uuid()::text, 1, 6),
           'starter'
         ) RETURNING id INTO new_org_id;

         INSERT INTO public.workspaces (org_id, name, slug)
         VALUES (new_org_id, 'My Workspace', 'my-workspace')
         RETURNING id INTO new_workspace_id;

         INSERT INTO public.org_members (org_id, user_id, role, joined_at)
         VALUES (new_org_id, NEW.id, 'owner', now());

         RETURN NEW;
       END;
       $$;

       CREATE TRIGGER on_auth_user_created
         AFTER INSERT ON auth.users
         FOR EACH ROW EXECUTE PROCEDURE public.handle_new_user();
       ```

    6. Create a custom SQL migration for the Supabase custom access token hook (FOUN-03, FOUN-04). This is CRITICAL — without it, `auth.jwt()->>'org_id'` returns null and ALL RLS policies fail:

       ```sql
       -- Custom Access Token Hook: injects org_id and user_role into JWT claims
       -- Source: https://supabase.com/docs/guides/auth/auth-hooks/custom-access-token-hook
       -- MUST be registered in Supabase Dashboard: Auth > Hooks > Custom Access Token
       CREATE OR REPLACE FUNCTION public.custom_access_token_hook(event jsonb)
       RETURNS jsonb
       LANGUAGE plpgsql
       SECURITY DEFINER
       SET search_path = public
       AS $$
       DECLARE
         claims jsonb;
         user_org_id uuid;
         user_role text;
       BEGIN
         -- Look up the user's primary org membership
         SELECT om.org_id, om.role
         INTO user_org_id, user_role
         FROM public.org_members om
         WHERE om.user_id = (event->>'user_id')::uuid
         LIMIT 1;

         claims := event->'claims';

         IF user_org_id IS NOT NULL THEN
           claims := jsonb_set(claims, '{org_id}', to_jsonb(user_org_id::text));
           claims := jsonb_set(claims, '{user_role}', to_jsonb(user_role));
         END IF;

         RETURN jsonb_build_object('claims', claims);
       END;
       $$;

       -- Grant execute to supabase_auth_admin role (required for auth hooks)
       GRANT EXECUTE ON FUNCTION public.custom_access_token_hook TO supabase_auth_admin;

       -- Revoke from public to prevent unauthorized calls
       REVOKE EXECUTE ON FUNCTION public.custom_access_token_hook FROM PUBLIC;
       REVOKE EXECUTE ON FUNCTION public.custom_access_token_hook FROM anon;
       REVOKE EXECUTE ON FUNCTION public.custom_access_token_hook FROM authenticated;
       ```

       **POST-MIGRATION MANUAL STEP:** After running migrations, the user MUST register this hook in the Supabase Dashboard: Authentication > Hooks > Custom Access Token > select `public.custom_access_token_hook` > Enable. Without this dashboard registration, the function exists but Supabase Auth will not call it and JWT claims will be empty.

    7. Run migrations against the Supabase database:
       ```bash
       npx drizzle-kit migrate
       ```
       If DATABASE_URL_DIRECT is not yet configured, document the migration command in the SUMMARY and note it must be run after Supabase project setup.

    IMPORTANT: All custom SQL migration files must be placed in `src/db/migrations/` with proper sequential naming so Drizzle's migration runner picks them up. If Drizzle's migration runner doesn't support custom SQL files in the generated directory, create a separate `src/db/migrations/custom/` directory and document the execution order.
  </action>
  <verify>
    - `npx drizzle-kit generate` runs without errors
    - Migration files exist in `src/db/migrations/`
    - Custom SQL files include: metric_events (with PARTITION BY), RLS policies, Vault functions, org provisioning trigger, custom access token hook
    - `npx tsc --noEmit` passes (schema files have no type errors)
    - If database is accessible: `npx drizzle-kit migrate` succeeds and tables are created
  </verify>
  <done>
    All database tables are defined in Drizzle schema files and generated as migrations. metric_events is partitioned by recorded_at with monthly partitions. RLS policies enforce org isolation via JWT claims on all tenant-scoped tables. Custom access token hook injects org_id and user_role into JWT from org_members. Vault functions exist for encrypted credential storage. Org provisioning trigger auto-creates org + workspace + membership on new user signup.
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes with all schema files
2. `npx drizzle-kit generate` creates migration SQL
3. Migration directory contains: Drizzle-generated SQL + custom SQL for metric_events partitioning, RLS policies, Vault functions, and org provisioning trigger
4. organizations table includes planTier, featureFlags, whiteLabelConfig columns
5. metric_events has PARTITION BY RANGE (recorded_at) with at least 4 monthly partitions
6. All RLS policies use `auth.jwt()->>'org_id'` — no subqueries except the documented workspace_members exception
7. Vault functions are restricted to service_role only
8. `custom_access_token_hook` function exists and is granted to `supabase_auth_admin`
9. Partitioning rationale is documented in the migration file (RANGE on recorded_at only — intentional divergence from spec)
</verification>

<success_criteria>
- Complete multi-tenant schema: org → workspace → store hierarchy with all FOUN requirements
- metric_events partitioned by recorded_at (monthly)
- metric_definitions, sync_jobs, integration_connections tables defined
- RLS active on all tenant tables with JWT claim-based policies
- Vault helper functions for encrypted credential storage
- Org auto-provisioning trigger on auth.users insert
- Custom access token hook injects org_id and user_role into JWT claims
- All migrations generated and ready to apply
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-02-SUMMARY.md`
</output>
